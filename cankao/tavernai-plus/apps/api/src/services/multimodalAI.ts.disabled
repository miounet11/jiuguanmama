const { PrismaClient } = require('../../node_modules/.prisma/client')
import OpenAI from 'openai'
import fs from 'fs/promises'
import path from 'path'
import axios from 'axios'

const prisma = new PrismaClient()

// 多模态AI服务配置
interface AIProviderConfig {
  name: string
  apiKey: string
  baseUrl?: string
  models: {
    text: string[]
    image: string[]
    speech: string[]
  }
  isActive: boolean
  priority: number
}

// 语音配置
interface VoiceConfig {
  provider: 'openai' | 'elevenlabs' | 'azure'
  voice: string
  speed: number
  pitch: number
  stability?: number
}

// 图像生成配置
interface ImageConfig {
  provider: 'openai' | 'midjourney' | 'stablediffusion'
  style: string
  quality: 'standard' | 'hd'
  size: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792'
  steps?: number
}

class MultimodalAIService {
  private openai: OpenAI
  private providers: Map<string, AIProviderConfig> = new Map()

  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })
    this.loadProviders()
  }

  // 加载AI提供商配置
  private async loadProviders() {
    try {
      const providers = await prisma.aIProvider.findMany({
        where: { isActive: true },
        orderBy: { priority: 'asc' }
      })

      for (const provider of providers) {
        this.providers.set(provider.name, {
          name: provider.name,
          apiKey: provider.apiKey,
          baseUrl: provider.baseUrl || undefined,
          models: JSON.parse(provider.models),
          isActive: provider.isActive,
          priority: provider.priority
        })
      }

      console.log(`✅ 已加载 ${providers.length} 个AI提供商配置`)
    } catch (error) {
      console.error('❌ 加载AI提供商配置失败:', error)
    }
  }

  // 文本生成
  async generateText(prompt: string, options: {
    characterId?: string
    userId: string
    model?: string
    temperature?: number
    maxTokens?: number
    systemPrompt?: string
  }): Promise<{
    content: string
    usage: {
      promptTokens: number
      completionTokens: number
      totalTokens: number
    }
    cost: number
  }> {
    const startTime = Date.now()

    try {
      // 获取角色信息和系统提示
      let systemPrompt = options.systemPrompt || ''
      if (options.characterId) {
        const character = await prisma.character.findUnique({
          where: { id: options.characterId }
        })
        if (character) {
          systemPrompt = this.buildCharacterSystemPrompt(character)
        }
      }

      const response = await this.openai.chat.completions.create({
        model: options.model || 'gpt-4',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: prompt }
        ],
        temperature: options.temperature || 0.7,
        max_tokens: options.maxTokens || 1000
      })

      const content = response.choices[0]?.message?.content || ''
      const usage = response.usage!
      const cost = this.calculateCost('text', usage.total_tokens)

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'text',
        provider: 'openai',
        model: options.model || 'gpt-4',
        inputTokens: usage.prompt_tokens,
        outputTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
        cost,
        duration: Date.now() - startTime,
        characterId: options.characterId
      })

      return {
        content,
        usage: {
          promptTokens: usage.prompt_tokens,
          completionTokens: usage.completion_tokens,
          totalTokens: usage.total_tokens
        },
        cost
      }
    } catch (error) {
      console.error('文本生成失败:', error)
      throw new Error('文本生成服务暂时不可用')
    }
  }

  // 语音合成
  async synthesizeSpeech(text: string, options: {
    userId: string
    characterId?: string
    voiceConfig?: VoiceConfig
  }): Promise<{
    audioUrl: string
    duration: number
    cost: number
  }> {
    const startTime = Date.now()

    try {
      // 获取角色语音配置
      let voiceConfig = options.voiceConfig
      if (options.characterId && !voiceConfig) {
        const voiceProfile = await prisma.voiceProfile.findFirst({
          where: { characterId: options.characterId }
        })
        if (voiceProfile) {
          voiceConfig = JSON.parse(voiceProfile.config)
        }
      }

      // 默认语音配置
      voiceConfig = voiceConfig || {
        provider: 'openai',
        voice: 'alloy',
        speed: 1.0,
        pitch: 1.0
      }

      const response = await this.openai.audio.speech.create({
        model: 'tts-1',
        voice: voiceConfig.voice as any,
        input: text,
        speed: voiceConfig.speed
      })

      // 生成文件名和保存路径
      const fileName = `speech_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.mp3`
      const filePath = path.join(process.cwd(), 'uploads', 'audio', fileName)

      // 确保目录存在
      await fs.mkdir(path.dirname(filePath), { recursive: true })

      // 保存音频文件
      const arrayBuffer = await response.arrayBuffer()
      await fs.writeFile(filePath, Buffer.from(arrayBuffer))

      const audioUrl = `/uploads/audio/${fileName}`
      const duration = await this.getAudioDuration(filePath)
      const cost = this.calculateCost('tts', text.length)

      // 保存媒体文件记录
      await prisma.mediaFile.create({
        data: {
          userId: options.userId,
          type: 'audio',
          originalName: fileName,
          fileName,
          filePath: audioUrl,
          mimeType: 'audio/mpeg',
          size: Buffer.from(arrayBuffer).length,
          duration,
          metadata: JSON.stringify({ voiceConfig, characterId: options.characterId })
        }
      })

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'tts',
        provider: 'openai',
        model: 'tts-1',
        inputTokens: text.length,
        outputTokens: 0,
        totalTokens: text.length,
        cost,
        duration: Date.now() - startTime,
        characterId: options.characterId,
        outputUrl: audioUrl
      })

      return {
        audioUrl,
        duration,
        cost
      }
    } catch (error) {
      console.error('语音合成失败:', error)
      throw new Error('语音合成服务暂时不可用')
    }
  }

  // 语音转文字
  async transcribeAudio(audioFilePath: string, options: {
    userId: string
    language?: string
  }): Promise<{
    text: string
    language: string
    confidence: number
    cost: number
  }> {
    const startTime = Date.now()

    try {
      const audioFile = await fs.readFile(audioFilePath)

      const response = await this.openai.audio.transcriptions.create({
        file: new File([audioFile], path.basename(audioFilePath)),
        model: 'whisper-1',
        language: options.language || 'zh',
        response_format: 'verbose_json'
      })

      const cost = this.calculateCost('stt', audioFile.length)

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'stt',
        provider: 'openai',
        model: 'whisper-1',
        inputTokens: audioFile.length,
        outputTokens: response.text.length,
        totalTokens: audioFile.length + response.text.length,
        cost,
        duration: Date.now() - startTime
      })

      return {
        text: response.text,
        language: response.language || 'zh',
        confidence: 0.95, // Whisper doesn't provide confidence, using default
        cost
      }
    } catch (error) {
      console.error('语音转文字失败:', error)
      throw new Error('语音转文字服务暂时不可用')
    }
  }

  // 图像生成
  async generateImage(prompt: string, options: {
    userId: string
    characterId?: string
    imageConfig?: ImageConfig
  }): Promise<{
    imageUrl: string
    cost: number
    revisedPrompt?: string
  }> {
    const startTime = Date.now()

    try {
      const imageConfig = options.imageConfig || {
        provider: 'openai',
        style: 'natural',
        quality: 'standard',
        size: '1024x1024'
      }

      const response = await this.openai.images.generate({
        model: 'dall-e-3',
        prompt: prompt,
        n: 1,
        quality: imageConfig.quality,
        size: imageConfig.size,
        style: imageConfig.style as 'natural' | 'vivid'
      })

      const imageUrl = response.data?.[0]?.url!
      const revisedPrompt = response.data?.[0]?.revised_prompt

      // 下载并保存图像
      const imageResponse = await axios.get(imageUrl, { responseType: 'arraybuffer' })
      const fileName = `image_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.png`
      const filePath = path.join(process.cwd(), 'uploads', 'images', fileName)

      await fs.mkdir(path.dirname(filePath), { recursive: true })
      await fs.writeFile(filePath, imageResponse.data)

      const localImageUrl = `/uploads/images/${fileName}`
      const cost = this.calculateCost('image', 1)

      // 保存媒体文件记录
      await prisma.mediaFile.create({
        data: {
          userId: options.userId,
          type: 'image',
          originalName: fileName,
          fileName,
          filePath: localImageUrl,
          mimeType: 'image/png',
          size: imageResponse.data.length,
          metadata: JSON.stringify({
            imageConfig,
            characterId: options.characterId,
            originalPrompt: prompt,
            revisedPrompt
          })
        }
      })

      // 保存图像生成记录
      await prisma.imageGeneration.create({
        data: {
          userId: options.userId,
          characterId: options.characterId,
          prompt: prompt,
          revisedPrompt,
          imageUrl: localImageUrl,
          model: 'dall-e-3',
          style: imageConfig.style,
          quality: imageConfig.quality,
          size: imageConfig.size,
          cost
        }
      })

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'image',
        provider: 'openai',
        model: 'dall-e-3',
        inputTokens: prompt.length,
        outputTokens: 1,
        totalTokens: prompt.length + 1,
        cost,
        duration: Date.now() - startTime,
        characterId: options.characterId,
        outputUrl: localImageUrl
      })

      return {
        imageUrl: localImageUrl,
        cost,
        revisedPrompt
      }
    } catch (error) {
      console.error('图像生成失败:', error)
      throw new Error('图像生成服务暂时不可用')
    }
  }

  // 图像分析
  async analyzeImage(imageUrl: string, prompt: string, options: {
    userId: string
    characterId?: string
  }): Promise<{
    analysis: string
    cost: number
  }> {
    const startTime = Date.now()

    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4-vision-preview',
        messages: [
          {
            role: 'user',
            content: [
              { type: 'text', text: prompt },
              { type: 'image_url', image_url: { url: imageUrl } }
            ]
          }
        ],
        max_tokens: 500
      })

      const analysis = response.choices[0]?.message?.content || ''
      const cost = this.calculateCost('vision', response.usage?.total_tokens || 0)

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'vision',
        provider: 'openai',
        model: 'gpt-4-vision-preview',
        inputTokens: response.usage?.prompt_tokens || 0,
        outputTokens: response.usage?.completion_tokens || 0,
        totalTokens: response.usage?.total_tokens || 0,
        cost,
        duration: Date.now() - startTime,
        characterId: options.characterId
      })

      return {
        analysis,
        cost
      }
    } catch (error) {
      console.error('图像分析失败:', error)
      throw new Error('图像分析服务暂时不可用')
    }
  }

  // 获取可用模型列表
  async getAvailableModels(): Promise<{
    text: string[]
    image: string[]
    speech: string[]
  }> {
    const models = {
      text: ['gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo', 'claude-3-opus', 'claude-3-sonnet'],
      image: ['dall-e-3', 'dall-e-2', 'midjourney', 'stable-diffusion'],
      speech: ['tts-1', 'tts-1-hd', 'elevenlabs', 'azure-speech']
    }

    return models
  }

  // 获取使用统计
  async getUsageStats(userId: string, timeRange: {
    startDate: Date
    endDate: Date
  }): Promise<{
    totalRequests: number
    totalCost: number
    breakdown: {
      text: { requests: number; cost: number }
      image: { requests: number; cost: number }
      speech: { requests: number; cost: number }
    }
  }> {
    const requests = await prisma.aIRequest.findMany({
      where: {
        userId,
        createdAt: {
          gte: timeRange.startDate,
          lte: timeRange.endDate
        }
      }
    })

    const stats = {
      totalRequests: requests.length,
      totalCost: requests.reduce((sum: any, req: any) => sum + req.cost, 0),
      breakdown: {
        text: { requests: 0, cost: 0 },
        image: { requests: 0, cost: 0 },
        speech: { requests: 0, cost: 0 }
      }
    }

    for (const request of requests) {
      if (['text', 'tts', 'stt'].includes(request.type)) {
        const category = request.type === 'text' ? 'text' : 'speech'
        stats.breakdown[category].requests++
        stats.breakdown[category].cost += request.cost
      } else if (['image', 'vision'].includes(request.type)) {
        stats.breakdown.image.requests++
        stats.breakdown.image.cost += request.cost
      }
    }

    return stats
  }

  // 私有方法：构建角色系统提示
  private buildCharacterSystemPrompt(character: any): string {
    let systemPrompt = `你是${character.name}。`

    if (character.personality) {
      systemPrompt += `\n性格特征：${character.personality}`
    }

    if (character.backstory) {
      systemPrompt += `\n背景故事：${character.backstory}`
    }

    if (character.speakingStyle) {
      systemPrompt += `\n说话风格：${character.speakingStyle}`
    }

    if (character.scenario) {
      systemPrompt += `\n当前场景：${character.scenario}`
    }

    systemPrompt += '\n\n请始终保持角色设定，用中文回应。'

    return systemPrompt
  }

  // 私有方法：计算使用成本
  private calculateCost(type: string, units: number): number {
    const pricing = {
      text: 0.002,      // 每1000 tokens
      tts: 0.015,       // 每1000字符
      stt: 0.006,       // 每分钟
      image: 0.04,      // 每张图像
      vision: 0.01      // 每1000 tokens
    }

    const rate = pricing[type as keyof typeof pricing] || 0

    switch (type) {
      case 'text':
      case 'vision':
        return (units / 1000) * rate
      case 'tts':
        return (units / 1000) * rate
      case 'stt':
        return (units / 60) * rate // 假设1MB音频约1分钟
      case 'image':
        return rate
      default:
        return 0
    }
  }

  // 私有方法：记录AI请求
  private async logAIRequest(data: {
    userId: string
    type: string
    provider: string
    model: string
    inputTokens: number
    outputTokens: number
    totalTokens: number
    cost: number
    duration: number
    characterId?: string
    outputUrl?: string
  }) {
    try {
      await prisma.aIRequest.create({
        data: {
          userId: data.userId,
          type: data.type,
          provider: data.provider,
          model: data.model,
          inputTokens: data.inputTokens,
          outputTokens: data.outputTokens,
          totalTokens: data.totalTokens,
          cost: data.cost,
          duration: data.duration,
          characterId: data.characterId,
          outputUrl: data.outputUrl,
          metadata: JSON.stringify({
            timestamp: new Date().toISOString(),
            userAgent: 'TavernAI-Plus'
          })
        }
      })
    } catch (error) {
      console.error('记录AI请求失败:', error)
    }
  }

  // 私有方法：获取音频时长
  private async getAudioDuration(filePath: string): Promise<number> {
    // 这里应该使用ffprobe或类似工具获取真实时长
    // 暂时返回估算值
    const stats = await fs.stat(filePath)
    return Math.round(stats.size / 1000) // 粗略估算：1KB约1秒
  }

  /**
   * AI驱动的关键词提取和实体识别
   * 为动态世界观注入系统提供支持
   */
  async extractKeywordsAI(text: string, options: {
    userId: string
    language?: string
    entityTypes?: string[]
    maxKeywords?: number
  }): Promise<{
    keywords: string[]
    entities: Array<{
      text: string
      type: 'PERSON' | 'LOCATION' | 'ORGANIZATION' | 'EVENT' | 'ITEM' | 'CONCEPT'
      confidence: number
      startOffset: number
      endOffset: number
    }>
    themes: string[]
    sentiment: {
      score: number // -1 to 1
      magnitude: number
      emotion: string
    }
    cost: number
  }> {
    const startTime = Date.now()

    try {
      const prompt = `请分析以下文本，提取关键词和实体信息：

文本内容：
${text}

请返回JSON格式结果，包含：
1. keywords: 重要关键词列表（最多${options.maxKeywords || 15}个）
2. entities: 实体识别结果，包含文本、类型、置信度、位置
3. themes: 主要主题列表
4. sentiment: 情感分析（分数-1到1、强度0到1、主要情绪）

实体类型包括：PERSON（人物）、LOCATION（地点）、ORGANIZATION（组织）、EVENT（事件）、ITEM（物品）、CONCEPT（概念）

示例格式：
{
  "keywords": ["魔法", "学院", "冒险", "友谊"],
  "entities": [
    {
      "text": "霍格沃茨",
      "type": "LOCATION",
      "confidence": 0.95,
      "startOffset": 10,
      "endOffset": 14
    }
  ],
  "themes": ["教育", "成长", "冒险"],
  "sentiment": {
    "score": 0.3,
    "magnitude": 0.7,
    "emotion": "兴奋"
  }
}`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `你是专业的文本分析AI，擅长关键词提取、实体识别和情感分析。请分析${options.language || '中文'}文本并返回JSON格式结果。`
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: 1000
      })

      const content = response.choices[0]?.message?.content || '{}'
      const usage = response.usage!
      const cost = this.calculateCost('text', usage.total_tokens)

      let result
      try {
        result = JSON.parse(content)
      } catch (parseError) {
        // 降级处理：基于规则的关键词提取
        result = this.fallbackKeywordExtraction(text, options)
      }

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'keyword_extraction',
        provider: 'openai',
        model: 'gpt-4',
        inputTokens: usage.prompt_tokens,
        outputTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
        cost,
        duration: Date.now() - startTime
      })

      return {
        ...result,
        cost
      }
    } catch (error) {
      console.error('关键词提取失败:', error)
      // 降级处理
      const fallbackResult = this.fallbackKeywordExtraction(text, options)
      return {
        keywords: fallbackResult.keywords,
        entities: fallbackResult.entities,
        themes: fallbackResult.themes,
        sentiment: fallbackResult.sentiment,
        cost: 0
      }
    }
  }

  /**
   * 生成世界观信息智能摘要
   * 根据上下文和相关性生成合适长度的摘要
   */
  async generateWorldInfoSummary(
    content: string,
    context: {
      keywords: string[]
      themes: string[]
      maxLength: number
    },
    options: {
      userId: string
      preserveStyle?: boolean
    }
  ): Promise<{
    summary: string
    keyPoints: string[]
    relevanceScore: number
    cost: number
  }> {
    const startTime = Date.now()

    try {
      const prompt = `请为以下世界观内容生成摘要，重点关注与上下文相关的信息：

原始内容：
${content}

上下文关键词：${context.keywords.join('、')}
相关主题：${context.themes.join('、')}
摘要长度限制：${context.maxLength}字符

请返回JSON格式结果：
{
  "summary": "压缩后的摘要内容",
  "keyPoints": ["要点1", "要点2", "要点3"],
  "relevanceScore": 0.85
}

要求：
1. 摘要长度不超过${context.maxLength}字符
2. 保留与关键词和主题最相关的信息
3. ${options.preserveStyle ? '保持原文风格和语调' : '使用简洁明了的语言'}
4. relevanceScore表示摘要与上下文的相关性(0-1)`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: '你是专业的内容摘要专家，擅长提取关键信息并保持内容相关性。'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: Math.ceil(context.maxLength / 2)
      })

      const responseContent = response.choices[0]?.message?.content || '{}'
      const usage = response.usage!
      const cost = this.calculateCost('text', usage.total_tokens)

      let result
      try {
        result = JSON.parse(responseContent)
      } catch (parseError) {
        // 降级处理：简单截断
        result = {
          summary: content.substring(0, context.maxLength) + (content.length > context.maxLength ? '...' : ''),
          keyPoints: context.keywords.slice(0, 3),
          relevanceScore: 0.5
        }
      }

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'content_summary',
        provider: 'openai',
        model: 'gpt-3.5-turbo',
        inputTokens: usage.prompt_tokens,
        outputTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
        cost,
        duration: Date.now() - startTime
      })

      return {
        ...result,
        cost
      }
    } catch (error) {
      console.error('世界观摘要生成失败:', error)
      // 降级处理
      return {
        summary: content.substring(0, context.maxLength) + (content.length > context.maxLength ? '...' : ''),
        keyPoints: context.keywords.slice(0, 3),
        relevanceScore: 0.5,
        cost: 0
      }
    }
  }

  /**
   * 检测对话的情感上下文和语调
   * 用于优化世界观注入的时机和方式
   */
  async detectEmotionalContext(
    messages: Array<{ role: string; content: string }>,
    options: {
      userId: string
      characterId?: string
      includeAdvice?: boolean
    }
  ): Promise<{
    overallMood: string
    emotionalIntensity: number // 0-1
    appropriateForInjection: boolean
    suggestedTiming: 'immediate' | 'delayed' | 'avoid'
    contextAdvice?: string
    cost: number
  }> {
    const startTime = Date.now()

    try {
      const conversationText = messages.slice(-5).map(m =>
        `${m.role === 'user' ? '用户' : '角色'}: ${m.content}`
      ).join('\n')

      const prompt = `请分析以下对话的情感上下文，判断是否适合注入世界观信息：

对话内容：
${conversationText}

请返回JSON格式分析结果：
{
  "overallMood": "对话整体情绪（如：轻松、紧张、浪漫、严肃、激动等）",
  "emotionalIntensity": 0.75,
  "appropriateForInjection": true,
  "suggestedTiming": "immediate",
  ${options.includeAdvice ? '"contextAdvice": "关于何时何种方式注入世界观的建议",' : ''}
  "reasoning": "判断理由"
}

判断标准：
- 轻松、好奇的对话适合注入
- 紧张、激烈的对话建议延迟注入
- 私密、情感化的对话避免注入
- timing: immediate（立即）、delayed（延迟）、avoid（避免）`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: '你是对话情感分析专家，擅长判断对话氛围和适当的交互时机。'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: 300
      })

      const content = response.choices[0]?.message?.content || '{}'
      const usage = response.usage!
      const cost = this.calculateCost('text', usage.total_tokens)

      let result
      try {
        result = JSON.parse(content)
      } catch (parseError) {
        // 降级处理：保守策略
        result = {
          overallMood: '中性',
          emotionalIntensity: 0.5,
          appropriateForInjection: true,
          suggestedTiming: 'delayed',
          contextAdvice: '建议在对话间隙适当注入世界观信息'
        }
      }

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'emotional_analysis',
        provider: 'openai',
        model: 'gpt-3.5-turbo',
        inputTokens: usage.prompt_tokens,
        outputTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
        cost,
        duration: Date.now() - startTime,
        characterId: options.characterId
      })

      return {
        ...result,
        cost
      }
    } catch (error) {
      console.error('情感上下文检测失败:', error)
      // 降级处理：保守策略
      return {
        overallMood: '中性',
        emotionalIntensity: 0.5,
        appropriateForInjection: true,
        suggestedTiming: 'delayed',
        contextAdvice: '建议在对话间隙适当注入世界观信息',
        cost: 0
      }
    }
  }

  /**
   * 为角色语音优化世界观内容
   * 调整内容以匹配特定角色的语言风格
   */
  async optimizeForCharacterVoice(
    content: string,
    character: {
      name: string
      personality?: string
      speakingStyle?: string
    },
    options: {
      userId: string
      tone?: 'formal' | 'casual' | 'mysterious' | 'friendly'
      length?: 'brief' | 'normal' | 'detailed'
    }
  ): Promise<{
    optimizedContent: string
    voiceMatching: number // 0-1, 与角色语音的匹配度
    adjustments: string[]
    cost: number
  }> {
    const startTime = Date.now()

    try {
      const prompt = `请将以下世界观内容调整为符合特定角色语言风格的表达方式：

原始内容：
${content}

角色信息：
- 名称：${character.name}
- 性格：${character.personality || '未知'}
- 说话风格：${character.speakingStyle || '未知'}

调整要求：
- 语调：${options.tone || 'friendly'}
- 长度：${options.length || 'normal'}

请返回JSON格式结果：
{
  "optimizedContent": "调整后的内容",
  "voiceMatching": 0.9,
  "adjustments": ["调整说明1", "调整说明2"],
  "styleNotes": "风格调整要点"
}

要求：
1. 保持信息准确性，只调整表达方式
2. 符合角色的性格和说话习惯
3. 自然融入对话，不显得突兀`

      const response = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: '你是角色语音优化专家，擅长调整文本以匹配不同角色的说话风格和个性。'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 500
      })

      const responseContent = response.choices[0]?.message?.content || '{}'
      const usage = response.usage!
      const cost = this.calculateCost('text', usage.total_tokens)

      let result
      try {
        result = JSON.parse(responseContent)
      } catch (parseError) {
        // 降级处理：返回原始内容
        result = {
          optimizedContent: content,
          voiceMatching: 0.7,
          adjustments: ['保持原始内容'],
          styleNotes: '未进行风格调整'
        }
      }

      // 记录AI请求
      await this.logAIRequest({
        userId: options.userId,
        type: 'voice_optimization',
        provider: 'openai',
        model: 'gpt-3.5-turbo',
        inputTokens: usage.prompt_tokens,
        outputTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
        cost,
        duration: Date.now() - startTime
      })

      return {
        ...result,
        cost
      }
    } catch (error) {
      console.error('角色语音优化失败:', error)
      // 降级处理
      return {
        optimizedContent: content,
        voiceMatching: 0.7,
        adjustments: ['保持原始内容'],
        cost: 0
      }
    }
  }

  /**
   * 降级处理：基于规则的关键词提取
   */
  private fallbackKeywordExtraction(text: string, options: any) {
    // 常见关键词列表
    const commonKeywords = [
      '魔法', '法术', '咒语', '法师', '巫师',
      '学院', '学校', '教育', '学习', '知识',
      '冒险', '探索', '旅行', '任务', '挑战',
      '战斗', '战争', '胜利', '失败', '勇气',
      '友谊', '爱情', '家族', '伙伴', '敌人',
      '王国', '城市', '村庄', '森林', '山脉',
      '剑', '盾', '武器', '装备', '宝物',
      '传说', '神话', '历史', '秘密', '谜团'
    ]

    const detectedKeywords = commonKeywords.filter(keyword =>
      text.toLowerCase().includes(keyword)
    ).slice(0, options.maxKeywords || 15)

    // 简单的实体识别（基于大写字母和特定模式）
    const entities: Array<{
      text: string;
      type: 'PERSON' | 'LOCATION' | 'ORGANIZATION' | 'EVENT' | 'ITEM' | 'CONCEPT';
      confidence: number;
      startOffset: number;
      endOffset: number;
    }> = []
    const entityPatterns = [
      { regex: /[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*/g, type: 'PERSON' as const },
      { regex: /(?:学院|城市|王国|森林|山脉)[^，。！？\s]*/g, type: 'LOCATION' as const }
    ]

    entityPatterns.forEach(pattern => {
      const matches = text.match(pattern.regex) || []
      matches.forEach(match => {
        entities.push({
          text: match,
          type: pattern.type,
          confidence: 0.6,
          startOffset: text.indexOf(match),
          endOffset: text.indexOf(match) + match.length
        })
      })
    })

    return {
      keywords: detectedKeywords,
      entities: entities.slice(0, 10),
      themes: detectedKeywords.slice(0, 5),
      sentiment: {
        score: 0,
        magnitude: 0.5,
        emotion: '中性'
      }
    }
  }
}

export default new MultimodalAIService()
